{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6775ba0c",
   "metadata": {},
   "source": [
    "# 99_he_week_5\n",
    "\n",
    "Installation guide on linux: https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/week_5_batch_processing/setup/linux.md\n",
    "\n",
    "* Recommended to be done on a remote VM\n",
    "\n",
    "```bash\n",
    "export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.5-src.zip:$PYTHONPATH\"\n",
    "export PYTHONPATH=\"${SPARK_HOME}/python/:$PYTHONPATH\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4faba719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "266750d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099dd44f",
   "metadata": {},
   "source": [
    "Q1: Install Spark and PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f98a98a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c666df5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af991e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing download: https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz\n",
      "File size: 167.655 Megabyte(s) (175799316 bytes)\n",
      "Opening output file data/fhvhv_tripdata_2021-06.csv.gz\n",
      "Starting download\n",
      "\n",
      "Connection 0 finished            2           3            ] [  13.9MB/s] [00:08]\u001b[2K\n",
      "Connection 1 finished............2     0     3            ] [  11.7MB/s] [00:07]\u001b[2K\n",
      "Connection 2 finished..................2     3     1      ] [  10.6MB/s] [00:05]\u001b[2K\n",
      "Connection 0 finished........................3     1  2   ] [  10.2MB/s] [00:03]\u001b[2K [  10.4MB/s] [00:04]\n",
      "Connection 3 finished...........................3  1  2   ] [   9.9MB/s] [00:02]\u001b[2K\n",
      "Connection 0 finished..............................1  2 3 ] [   9.8MB/s] [00:01]\u001b[2K\n",
      "Connection 1 finished................................12 3 ] [   9.7MB/s] [00:00]\u001b[2K\n",
      "Connection 0 finished..................................23 ] [   9.7MB/s] [00:00]\u001b[2K\n",
      "Connection 2 finished..................................230] [   9.7MB/s] [00:00]\u001b[2K\n",
      "Connection 1 finished...................................32] [   9.6MB/s] [00:00]\u001b[2K\n",
      "Connection 3 finished...................................32] [   9.7MB/s] [00:00]\u001b[2K\n",
      "Connection 0 finished...................................13] [   9.5MB/s] [00:00]\u001b[2K\n",
      "Connection 2 finished....................................3] [   9.5MB/s] [00:00]\u001b[2K\n",
      "Connection 1 finished....................................3] [   9.5MB/s] [00:00]\u001b[2K\n",
      "Connection 3 finished....................................3] [   9.1MB/s] [00:00]\u001b[2K\n",
      "Connection 0 finished....................................3] [   9.0MB/s] [00:00]\u001b[2K\n",
      "Connection 1 finished....................................3] [   8.8MB/s] [00:00]\u001b[2K\n",
      "Connection 3 finished....................................3] [   8.7MB/s] [00:00]\u001b[2K\n",
      "Connection 2 finished....................................3] [   8.6MB/s] [00:00]\u001b[2K\n",
      "Connection 1 finished....................................3] [   8.5MB/s] [00:00]\u001b[2K\n",
      "Connection 3 finished....................................2] [   8.4MB/s] [00:00]\u001b[2K\n",
      "Connection 2 finished....................................0] [   8.3MB/s] [00:00]\u001b[2K\n",
      "Connection 0 finished....................................0] [   8.2MB/s] [00:00]\u001b[2K\n",
      "\n",
      "Downloaded 167.655 Megabyte(s) in 20 second(s). (8392.22 KB/s)\n"
     ]
    }
   ],
   "source": [
    "!rm -f data/fhvhv_tripdata_2021-06.csv.gz \n",
    "!axel https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz -o data/fhvhv_tripdata_2021-06.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06de24c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa3fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = pd.read_csv('data/fhvhv_tripdata_2021-06.csv.gz', nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1df35c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:02:41</td>\n",
       "      <td>2021-06-01 00:07:46</td>\n",
       "      <td>174</td>\n",
       "      <td>18</td>\n",
       "      <td>True</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:16:16</td>\n",
       "      <td>2021-06-01 00:21:14</td>\n",
       "      <td>32</td>\n",
       "      <td>254</td>\n",
       "      <td>True</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:27:01</td>\n",
       "      <td>2021-06-01 00:42:11</td>\n",
       "      <td>240</td>\n",
       "      <td>127</td>\n",
       "      <td>True</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:46:08</td>\n",
       "      <td>2021-06-01 00:53:45</td>\n",
       "      <td>127</td>\n",
       "      <td>235</td>\n",
       "      <td>True</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B02510</td>\n",
       "      <td>2021-06-01 00:45:42</td>\n",
       "      <td>2021-06-01 01:03:33</td>\n",
       "      <td>144</td>\n",
       "      <td>146</td>\n",
       "      <td>True</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num      pickup_datetime     dropoff_datetime  \\\n",
       "0               B02764  2021-06-01 00:02:41  2021-06-01 00:07:46   \n",
       "1               B02764  2021-06-01 00:16:16  2021-06-01 00:21:14   \n",
       "2               B02764  2021-06-01 00:27:01  2021-06-01 00:42:11   \n",
       "3               B02764  2021-06-01 00:46:08  2021-06-01 00:53:45   \n",
       "4               B02510  2021-06-01 00:45:42  2021-06-01 01:03:33   \n",
       "\n",
       "   PULocationID  DOLocationID  SR_Flag Affiliated_base_number  \n",
       "0           174            18     True                 B02764  \n",
       "1            32           254     True                 B02764  \n",
       "2           240           127     True                 B02764  \n",
       "3           127           235     True                 B02764  \n",
       "4           144           146     True                    nan  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fefc7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   dispatching_base_num    10000 non-null  object\n",
      " 1   pickup_datetime         10000 non-null  object\n",
      " 2   dropoff_datetime        10000 non-null  object\n",
      " 3   PULocationID            10000 non-null  int64 \n",
      " 4   DOLocationID            10000 non-null  int64 \n",
      " 5   SR_Flag                 10000 non-null  object\n",
      " 6   Affiliated_base_number  7286 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 547.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24eaa59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd['Affiliated_base_number'] = df_pd['Affiliated_base_number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b5e251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd['SR_Flag'] = df_pd['SR_Flag'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32fda245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/04 14:32:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08536fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropoff_datetime', StringType(), True), StructField('PULocationID', LongType(), True), StructField('DOLocationID', LongType(), True), StructField('SR_Flag', BooleanType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark.createDataFrame(df_pd).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d27841d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True), \n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True), \n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True), \n",
    "    types.StructField('PULocationID', types.LongType(), True), \n",
    "    types.StructField('DOLocationID', types.LongType(), True), \n",
    "    types.StructField('SR_Flag', types.BooleanType(), True), \n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "])\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4809641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying custom schema to data frame\n",
    "df = spark.read.format( \"csv\") \\\n",
    "    .schema(schema) \\\n",
    "    .option(\"header\", True) \\\n",
    "    .load(\"data/fhvhv_tripdata_2021-06.csv.gz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3f63d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.repartition(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f10eccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02395|2021-06-28 01:20:04|2021-06-28 01:33:26|          78|          69|   null|                B02395|\n",
      "|              B02510|2021-06-27 20:03:51|2021-06-27 20:14:55|         186|         107|   null|                  null|\n",
      "|              B02880|2021-06-21 08:35:42|2021-06-21 08:58:21|          36|         226|   null|                B02880|\n",
      "|              B02510|2021-06-29 18:02:10|2021-06-29 18:34:13|         193|         239|   null|                  null|\n",
      "|              B02682|2021-06-18 09:57:16|2021-06-18 10:30:37|          62|         211|   null|                B02682|\n",
      "|              B02510|2021-06-25 21:25:11|2021-06-25 21:44:31|          52|         114|   null|                  null|\n",
      "|              B02870|2021-06-20 14:27:12|2021-06-20 14:36:35|         116|          74|   null|                B02870|\n",
      "|              B02835|2021-06-01 09:55:25|2021-06-01 10:09:10|          75|          75|   null|                B02835|\n",
      "|              B02510|2021-06-23 18:07:24|2021-06-23 18:31:56|         114|         231|   null|                  null|\n",
      "|              B02875|2021-06-29 07:09:28|2021-06-29 07:25:20|          72|         225|   null|                B02875|\n",
      "|              B02883|2021-06-08 08:01:10|2021-06-08 08:13:51|         243|         169|   null|                B02883|\n",
      "|              B02882|2021-06-02 17:12:02|2021-06-02 17:25:56|         130|           9|   null|                B02882|\n",
      "|              B02866|2021-06-08 12:43:00|2021-06-08 12:50:36|         246|         158|   null|                B02866|\n",
      "|              B02866|2021-06-26 11:27:13|2021-06-26 11:58:45|          36|         148|   null|                B02866|\n",
      "|              B02877|2021-06-28 12:03:19|2021-06-28 12:48:50|         201|         188|   null|                B02877|\n",
      "|              B02887|2021-06-26 20:48:39|2021-06-26 21:02:12|         230|         186|   null|                B02887|\n",
      "|              B02869|2021-06-04 00:55:12|2021-06-04 01:12:51|         164|         238|   null|                B02869|\n",
      "|              B02510|2021-06-04 19:34:43|2021-06-04 19:52:55|         170|         249|   null|                  null|\n",
      "|              B02884|2021-06-13 04:28:56|2021-06-13 04:42:46|         232|         145|   null|                B02884|\n",
      "|              B02764|2021-06-28 20:16:21|2021-06-28 20:37:54|          25|         225|   null|                B02764|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8133d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "452468"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "df.filter(\n",
    "    (df.pickup_datetime > datetime.datetime(2021, 6, 15)) &\n",
    "    (df.pickup_datetime < datetime.datetime(2021, 6, 16))\n",
    "    ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ab67219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a user-defined function to get what is needed \n",
    "import datetime\n",
    "\n",
    "def udf_calculate_diff_in_hours(dropoff_datetime, pickup_datetime):\n",
    "    hours = dropoff_datetime - pickup_datetime\n",
    "    return (hours.total_seconds())/(60*60)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0f996dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "udfValueToCategory = udf(udf_calculate_diff_in_hours, types.FloatType())\n",
    "df_with_cat = df2.withColumn(\"time_diff\", udfValueToCategory(df2.dropoff_datetime, df2.pickup_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60269f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:===================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---------+\n",
      "|    pickup_datetime|   dropoff_datetime|time_diff|\n",
      "+-------------------+-------------------+---------+\n",
      "|2021-06-25 13:55:41|2021-06-28 08:48:25| 66.87889|\n",
      "|2021-06-22 12:09:45|2021-06-23 13:42:44|25.549723|\n",
      "|2021-06-27 10:32:29|2021-06-28 06:31:20|19.980833|\n",
      "|2021-06-26 22:37:11|2021-06-27 16:49:01|18.197222|\n",
      "|2021-06-23 20:40:43|2021-06-24 13:08:44|16.466944|\n",
      "|2021-06-23 22:03:31|2021-06-24 12:19:39|14.268888|\n",
      "|2021-06-24 23:11:00|2021-06-25 13:05:35|13.909722|\n",
      "|2021-06-04 20:56:02|2021-06-05 08:36:14|    11.67|\n",
      "|2021-06-27 07:45:19|2021-06-27 19:07:16|11.365833|\n",
      "|2021-06-20 17:05:12|2021-06-21 04:04:16|10.984445|\n",
      "|2021-06-01 12:25:29|2021-06-01 22:41:32|  10.2675|\n",
      "|2021-06-28 13:13:59|2021-06-28 23:11:58| 9.966389|\n",
      "|2021-06-01 12:01:46|2021-06-01 21:59:45| 9.966389|\n",
      "|2021-06-27 03:52:14|2021-06-27 13:30:30| 9.637777|\n",
      "|2021-06-18 08:50:29|2021-06-18 18:27:57| 9.624444|\n",
      "|2021-06-08 16:38:14|2021-06-09 02:07:03| 9.480278|\n",
      "|2021-06-11 23:26:20|2021-06-12 08:54:38| 9.471666|\n",
      "|2021-06-15 06:47:22|2021-06-15 16:11:30| 9.402223|\n",
      "|2021-06-25 02:32:24|2021-06-25 11:56:01| 9.393611|\n",
      "|2021-06-04 17:41:23|2021-06-05 03:04:00| 9.376945|\n",
      "+-------------------+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df_with_cat \\\n",
    "    .select( \\\n",
    "        col(\"pickup_datetime\"), \\\n",
    "        col(\"dropoff_datetime\"), \\\n",
    "        col(\"time_diff\"))  \\\n",
    "    .orderBy(\"time_diff\", ascending=False)\\\n",
    "    .show()\n",
    "#df_with_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d89df4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:======================================>                  (8 + 4) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|PULocationID| count|\n",
      "+------------+------+\n",
      "|          61|231279|\n",
      "|          79|221244|\n",
      "|         132|188867|\n",
      "|          37|187929|\n",
      "|          76|186780|\n",
      "|         231|164344|\n",
      "|         138|161596|\n",
      "|         234|158937|\n",
      "|         249|154698|\n",
      "|           7|152493|\n",
      "|         148|151020|\n",
      "|          68|147673|\n",
      "|          42|146402|\n",
      "|         255|143683|\n",
      "|         181|143594|\n",
      "|         225|141427|\n",
      "|          48|139611|\n",
      "|         246|139431|\n",
      "|          17|138428|\n",
      "|         170|137879|\n",
      "+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2.filter(\n",
    "    (df.pickup_datetime >= datetime.datetime(2021, 6, 1)) &\n",
    "    (df.pickup_datetime < datetime.datetime(2021, 7, 1))\n",
    "    ).groupBy('PULocationID').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98d64677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- SR_Flag: boolean (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7962e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = datetime.datetime(year=2021, month=6, day=1)\n",
    "time2 = datetime.datetime(year=2021, month=6, day=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "588863ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(udf_calculate_diff_in_hours(time2,time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba9cddde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- SR_Flag: boolean (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      " |-- time_diff: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_cat.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22fff26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
